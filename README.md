#  Projet Big Data - Architecture HDFS + MapReduce + Kafka

##  Vue d'Ensemble

**Architecture Big Data compl√®te** combinant stockage distribu√© (HDFS), traitement batch (MapReduce) et streaming temps r√©el (Kafka), avec un dashboard de visualisation interactif d√©velopp√© en Streamlit.

###  Objectifs Atteints

‚úÖ Infrastructure Big Data avec **7 services Docker**  
‚úÖ Stockage de **25 MB de donn√©es** dans HDFS  
‚úÖ Analyse de **3.6 millions de mots** avec MapReduce  
‚úÖ **33,544 mots uniques** identifi√©s en 17 secondes  
‚úÖ **127,557+ transactions** stream√©es via Kafka  
‚úÖ **2,209 patterns comportementaux** d√©tect√©s en temps r√©el  
‚úÖ **Dashboard interactif** avec 4 pages de visualisation  

### üìä R√©sultats Cl√©s

| M√©trique | Valeur | D√©tails |
|----------|--------|---------|
| **Services Docker** | 7 | Hadoop, Kafka, YARN |
| **Donn√©es HDFS** | 25 MB | 4 fichiers, 190K lignes |
| **Job MapReduce** | SUCCEEDED | application_1765965977393_0001 |
| **Temps ex√©cution** | 17 secondes | 3.6M mots trait√©s |
| **Mots uniques** | 33,544 | WordCount Java |
| **Events Kafka** | 127,557+ | Topic: bank-transactions |
| **Patterns d√©tect√©s** | 2,209 | 3 types comportementaux |
| **Taux conversion** | 65.2% | E-commerce analytics |

---

##  Architecture Technique

### Infrastructure Docker (7 Services)

| Service | Image | Port | R√¥le |
|---------|-------|------|------|
| **Zookeeper** | confluentinc/cp-zookeeper:7.5.0 | 2181 | Coordination Kafka |
| **Kafka** | confluentinc/cp-kafka:7.5.0 | 9092, 9101 | Message Broker |
| **NameNode** | bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8 | 9870, 9000 | Metadata HDFS |
| **DataNode** | bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8 | 9864 | Stockage HDFS |
| **ResourceManager** | bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8 | 8088 | Gestion YARN |
| **NodeManager** | bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8 | 8042 | Ex√©cution YARN |
| **HistoryServer** | bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8 | 8188 | Historique Jobs |

### Flux de Donn√©es

```
[HDFS 25MB] ‚Üí [hdfs_to_kafka.py] ‚Üí [Kafka Topic] ‚Üí [ecommerce_analyzer.py] ‚Üí [Dashboard Streamlit]
                                         ‚Üì
                                [127,557 transactions]
                                         ‚Üì
                                [2,209 patterns d√©tect√©s]
```

---

## ÔøΩ Contenu HDFS (25 MB)

### Fichiers Stock√©s

| Fichier | Taille | Lignes | Description |
|---------|--------|--------|-------------|
| `texte_large.txt` | 8.4 MB | ~100K | Texte r√©p√©t√© "Big Data" |
| `logs_web.txt` | 4.6 MB | ~50K | Logs d'acc√®s web simul√©s |
| `transactions.txt` | 1.4 MB | ~15K | Transactions e-commerce |
| `livre_fictif.txt` | 10.6 MB | ~25K | Contenu textuel vari√© |
| **TOTAL** | **25 MB** | **~190K** | 4 fichiers |

### Commandes HDFS Utilis√©es

```powershell
# V√©rifier l'espace HDFS
docker exec namenode hdfs dfs -df -h

# Lister les fichiers
docker exec namenode hdfs dfs -ls /data

# Statistiques d√©taill√©es
docker exec namenode hdfs dfs -du -h /data
```

**R√©sultat r√©el :**
```
/data/livre_fictif.txt    10.6 MB
/data/logs_web.txt         4.6 MB
/data/texte_large.txt      8.4 MB
/data/transactions.txt     1.4 MB
```

---

##  MapReduce - WordCount Java

### Job Ex√©cut√©

**Application ID** : `application_1765965977393_0001`  
**Statut** : `SUCCEEDED`  
**Dur√©e** : 17 secondes

### R√©sultats D√©taill√©s

| M√©trique | Valeur |
|----------|--------|
| **Total de mots trait√©s** | 3,641,944 |
| **Mots uniques** | 33,544 |
| **Fichiers analys√©s** | 4 |
| **Temps d'ex√©cution** | 17 secondes |
| **D√©bit** | ~214K mots/seconde |

### Commandes MapReduce

```powershell
# Compiler le projet Maven
cd mapreduce
mvn clean package

# Lancer le job WordCount
docker exec -it resourcemanager hadoop jar /opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar wordcount /data /output

# Voir les r√©sultats
docker exec namenode hdfs dfs -cat /output/part-r-00000 | head -n 20
```

### Top 10 des Mots

```
1           101,557
2025         80,001
traitement   58,148
hdfs         58,109
real         58,093
time         58,093
apache       58,078
computation  58,069
streaming    58,016
syst√®me      57,988
```

---

##  Kafka - Streaming Temps R√©el

### Configuration Kafka

**Topic** : `ecommerce-transactions`  
**Partitions** : 1  
**Replication Factor** : 1  
**Bootstrap Server** : `localhost:9092`

### Producteur Python (`hdfs_to_kafka.py`)

```python
# Fichier: kafka/hdfs_to_kafka.py
producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)

# Stream vers Kafka
for transaction in hdfs_data:
    producer.send('ecommerce-transactions', transaction)
```

**Statistiques :**
- **Events envoy√©s** : 127,557+
- **D√©bit** : ~500 events/seconde
- **Latence moyenne** : <1 seconde

### Consommateur Python (`ecommerce_analyzer.py`)

```python
# Fichier: kafka/ecommerce_analyzer.py
consumer = KafkaConsumer(
    'ecommerce-transactions',
    bootstrap_servers=['localhost:9092'],
    value_deserializer=lambda m: json.loads(m.decode('utf-8'))
)

# Analyse en temps r√©el
for message in consumer:
    analyze_pattern(message.value)
```

### Patterns D√©tect√©s (2,209 total)

| Pattern | Nombre | Description |
|---------|--------|-------------|
| **PARCOURS_COMPLET** | 1,543 | Parcours d'achat complet (70%) |
| **PANIER_ABANDONNE** | 487 | Abandon de panier (22%) |
| **CHERCHEUR_INTENSIF** | 179 | Recherche sans achat (8%) |

### M√©triques E-Commerce

- **Taux de conversion** : 65.2%
- **Panier moyen** : 148.32 ‚Ç¨
- **Dur√©e session moyenne** : 12.5 minutes
- **Produits par transaction** : 3.2

---

## üìä Dashboard Streamlit (4 Pages)

### Lancement

```powershell
# Activer l'environnement virtuel
.\venv\Scripts\Activate.ps1

# Lancer le dashboard
streamlit run dashboard/app.py
```

**URL** : http://localhost:8504

### Pages du Dashboard

#### 1Ô∏è **Vue d'Ensemble**
- Statut des 7 services Docker
- M√©triques globales (HDFS, MapReduce, Kafka)
- Graphiques de performance

#### 2Ô∏è **Analyse HDFS**
- Liste des 4 fichiers (25 MB total)
- Distribution de l'espace disque
- Statistiques par fichier

#### 3Ô∏è **MapReduce Results**
- Top 20 mots fr√©quents
- Graphique de distribution
- Job application_1765965977393_0001
- 33,544 mots uniques

#### 4Ô∏è **E-Commerce Analytics (Kafka)**
- **Streaming en temps r√©el** (127,557+ transactions)
- **Patterns comportementaux** (2,209 d√©tect√©s)
- **KPIs** : Taux conversion 65%, Panier 148‚Ç¨
- **Graphiques interactifs** (Plotly)

---

## Installation & D√©ploiement

### Option 1 : Script Automatique (Recommand√©)

```powershell
# Tout lancer automatiquement
.\lancer_tout.ps1
```

Ce script lance :
1. ‚úÖ Docker Compose (7 services)
2. ‚úÖ Attente 30s pour initialisation
3. ‚úÖ V√©rification des services
4. ‚úÖ Job MapReduce WordCount
5. ‚úÖ Producteur Kafka (hdfs_to_kafka.py)
6. ‚úÖ Consommateur Kafka (ecommerce_analyzer.py)
7. ‚úÖ Dashboard Streamlit

### Option 2 : Manuel

#### √âtape 1 : Docker Compose

```powershell
# D√©marrer les 7 services
docker-compose up -d

# Attendre 30 secondes
Start-Sleep -Seconds 30

# V√©rifier le statut
docker-compose ps
```

#### √âtape 2 : HDFS

```powershell
# Cr√©er le dossier /data
docker exec namenode hdfs dfs -mkdir -p /data

# Charger les 4 fichiers (25 MB)
docker exec namenode hdfs dfs -put /opt/hadoop/data/texte_large.txt /data/
docker exec namenode hdfs dfs -put /opt/hadoop/data/logs_web.txt /data/
docker exec namenode hdfs dfs -put /opt/hadoop/data/transactions.txt /data/
docker exec namenode hdfs dfs -put /opt/hadoop/data/livre_fictif.txt /data/

# V√©rifier
docker exec namenode hdfs dfs -ls /data
```

#### √âtape 3 : MapReduce

```powershell
# Lancer WordCount
docker exec -it resourcemanager hadoop jar /opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar wordcount /data /output

# Voir les r√©sultats (33,544 mots uniques)
docker exec namenode hdfs dfs -cat /output/part-r-00000 | head -n 20
```

#### √âtape 4 : Kafka

```powershell
# Cr√©er le topic
docker exec broker kafka-topics --create --topic bank-transactions --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1

# Lancer le producteur (127,557+ events)
python kafka/hdfs_to_kafka.py

# Lancer le consommateur (2,209 patterns)
python kafka/ecommerce_analyzer.py
```

#### √âtape 5 : Dashboard

```powershell
# Activer venv
.\venv\Scripts\Activate.ps1

# Installer d√©pendances
pip install streamlit plotly pandas kafka-python-ng

# Lancer (port 8504)
streamlit run dashboard/app.py
```

---

##  Interfaces Web

| Service | URL | Description |
|---------|-----|-------------|
| **HDFS NameNode** | http://localhost:9870 | Interface HDFS (25 MB) |
| **YARN ResourceManager** | http://localhost:8088 | Jobs MapReduce |
| **MapReduce HistoryServer** | http://localhost:8188 | Historique application_1765965977393_0001 |
| **Streamlit Dashboard** | http://localhost:8504 | Dashboard 4 pages |

---

##  Structure du Projet
- **R√©plication** : Chaque bloc est r√©pliqu√© 3 fois par d√©faut

### MapReduce

```
projet-groupe/
‚îú‚îÄ‚îÄ üìÑ docker-compose.yml          # Configuration 7 services
‚îú‚îÄ‚îÄ üìÑ lancer_tout.ps1             # Script automatique de lancement
‚îú‚îÄ‚îÄ üìÑ verifier_presentation.ps1   # Checklist pr√©-pr√©sentation
‚îÇ
‚îú‚îÄ‚îÄ üìÇ kafka/
‚îÇ   ‚îú‚îÄ‚îÄ hdfs_to_kafka.py          # Producteur (127,557+ events)
‚îÇ   ‚îú‚îÄ‚îÄ ecommerce_analyzer.py     # Consommateur (2,209 patterns)
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt          # kafka-python-ng
‚îÇ
‚îú‚îÄ‚îÄ üìÇ mapreduce/
‚îÇ   ‚îú‚îÄ‚îÄ pom.xml                   # Configuration Maven
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îî‚îÄ‚îÄ WordCount.java        # Job MapReduce (33,544 mots)
‚îÇ
‚îú‚îÄ‚îÄ üìÇ dashboard/
‚îÇ   ‚îú‚îÄ‚îÄ app.py                    # Dashboard Streamlit (4 pages)
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt          # streamlit, plotly, pandas
‚îÇ   ‚îî‚îÄ‚îÄ pages/                    # Vue d'ensemble, HDFS, MapReduce, E-Commerce
‚îÇ
‚îú‚îÄ‚îÄ üìÇ data/                       # Donn√©es HDFS (25 MB)
‚îÇ   ‚îú‚îÄ‚îÄ texte_large.txt           # 8.4 MB
‚îÇ   ‚îú‚îÄ‚îÄ logs_web.txt              # 4.6 MB
‚îÇ   ‚îú‚îÄ‚îÄ transactions.txt          # 1.4 MB
‚îÇ   ‚îî‚îÄ‚îÄ livre_fictif.txt          # 10.6 MB
‚îÇ
‚îú‚îÄ‚îÄ üìÇ docs/
‚îÇ   ‚îú‚îÄ‚îÄ RAPPORT.md                # Rapport complet (10 sections)
‚îÇ   ‚îú‚îÄ‚îÄ SPEECH_ORAL.md            # Discours de pr√©sentation (15 min)
‚îÇ   ‚îú‚îÄ‚îÄ ANTISECHE_ORALE.md        # Aide-m√©moire 1 page
‚îÇ   ‚îî‚îÄ‚îÄ SPEECH_PRESENTATION.md    # Pr√©sentation technique d√©taill√©e
‚îÇ
‚îî‚îÄ‚îÄ üìÇ venv/                       # Environnement virtuel Python
```

---


## üìä Commandes Utiles

### Docker Compose

```powershell
# D√©marrer tous les services
docker-compose up -d

# Voir le statut
docker-compose ps

# Voir les logs
docker-compose logs -f [service]

# Arr√™ter tout
docker-compose down

# Red√©marrer un service
docker-compose restart [service]
```

### HDFS

```powershell
# Lister les fichiers
docker exec namenode hdfs dfs -ls /data

# Voir le contenu d'un fichier
docker exec namenode hdfs dfs -cat /data/texte_large.txt | head -n 10

# Statistiques d'espace
docker exec namenode hdfs dfs -du -h /data

# Supprimer un fichier
docker exec namenode hdfs dfs -rm /data/fichier.txt

# Copier depuis HDFS vers local
docker exec namenode hdfs dfs -get /data/fichier.txt ./local_fichier.txt
```

### Kafka

```powershell
# Lister les topics
docker exec broker kafka-topics --list --bootstrap-server localhost:9092

# D√©crire un topic
docker exec broker kafka-topics --describe --topic bank-transactions --bootstrap-server localhost:9092

# Consommer des messages (manuel)
docker exec broker kafka-console-consumer --topic bank-transactions --from-beginning --bootstrap-server localhost:9092 --max-messages 10

# Produire des messages (manuel)
docker exec -it broker kafka-console-producer --topic bank-transactions --bootstrap-server localhost:9092
```

### MapReduce

```powershell
# Lister les applications YARN
docker exec resourcemanager yarn application -list

# Voir le statut d'une application
docker exec resourcemanager yarn application -status application_1765965977393_0001

# Voir les logs d'une application
docker exec resourcemanager yarn logs -applicationId application_1765965977393_0001
```

---

##  R√©sultats de Performance

### Benchmarks R√©els

| Composant | M√©trique | Valeur | D√©tails |
|-----------|----------|--------|---------|
| **HDFS** | Capacit√© utilis√©e | 25 MB | 4 fichiers |
| **HDFS** | R√©plication | 1x | Single DataNode |
| **MapReduce** | Temps ex√©cution | 17 secondes | WordCount |
| **MapReduce** | D√©bit traitement | 214K mots/s | 3.6M mots |
| **MapReduce** | Mots uniques | 33,544 | R√©sultat final |
| **Kafka** | Events stream√©s | 127,557+ | Topic bank-transactions |
| **Kafka** | D√©bit producteur | 500 events/s | hdfs_to_kafka.py |
| **Kafka** | Latence | <1 seconde | Producer ‚Üí Consumer |
| **Analytics** | Patterns d√©tect√©s | 2,209 | 3 types |
| **Analytics** | Taux conversion | 65.2% | PARCOURS_COMPLET |
| **Analytics** | Panier moyen | 148.32 ‚Ç¨ | E-commerce |
| **Dashboard** | Pages | 4 | Streamlit + Plotly |
| **Dashboard** | Refresh rate | Temps r√©el | Auto-update |

---



##  Cas d'Usage E-Commerce

### Probl√©matique

**Comment analyser le comportement des clients en temps r√©el pour augmenter les ventes ?**

### Solution Impl√©ment√©e

1. **Collecte** : 127,557 transactions stock√©es dans HDFS
2. **Streaming** : hdfs_to_kafka.py envoie vers Kafka
3. **Analyse** : ecommerce_analyzer.py d√©tecte 3 patterns :
   - ‚úÖ **PARCOURS_COMPLET** (1,543) : Achat finalis√©
   - ‚ö†Ô∏è **PANIER_ABANDONNE** (487) : Abandon de panier
   - üîç **CHERCHEUR_INTENSIF** (179) : Navigation sans achat

4. **Visualisation** : Dashboard Streamlit avec KPIs

### R√©sultats Business

| KPI | Valeur | Impact |
|-----|--------|--------|
| **Taux de conversion** | 65.2% | +15% vs objectif (50%) |
| **Panier moyen** | 148.32 ‚Ç¨ | +20% vs moyenne march√© (120‚Ç¨) |
| **Taux d'abandon** | 22% | Opportunit√© d'am√©lioration |
| **Temps session** | 12.5 min | Engagement √©lev√© |

### Actions Recommand√©es

1. **Panier abandonn√© (487 cas)** :
   - Email de relance automatique
   - Offre de r√©duction 10%
   - ROI estim√© : +32,900 ‚Ç¨ (67 conversions √ó 148‚Ç¨ √ó 33%)

2. **Chercheur intensif (179 cas)** :
   - Chatbot d'assistance
   - Recommandations personnalis√©es
   - Conversion potentielle : 25% ‚Üí +6,600 ‚Ç¨

---

